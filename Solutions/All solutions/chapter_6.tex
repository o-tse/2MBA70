
\textbf{Problem 6.2}
\begin{enumerate}[label=(\alph*)]
\item The implication from right to left is by definition of $\overleftarrow{F}$ and the fact that $F$ is non-decreasing. The implication from left to right is because $F$ is right continuous.
\item Consider the preimage of $(-\infty, t]$ under $X$. Then, using the above observation, we have
\begin{align*}
	X^{-1}((-\infty,t]) &= \{\omega \in \Omega \, : \, \overleftarrow{F}(U(\omega)) \in (-\infty,t]\}\\
	&= \{\omega \in \Omega \, :\ , U(\omega) \in (-\infty, F(t)]\} = U^{-1}((-\infty, F(t)]) \in \cB_{[0,1]}.
\end{align*}
Hence, $X$ is measurable. Finally, the above computation, together with Lemma 6.5, also implies that
\[
	\bbP\left(X^{-1}((-\infty,t])\right) = \bbP\left(U^{-1}((-\infty, F(t)])\right) = F(t).
\]
\end{enumerate}


Now let $(\Omega,\cF, \bbP)$ be a probability space and $U$ a standard normal random variable. We will show that $X = \overleftarrow{F} \circ U$ is a random variable with the right probability measure. Since we can construct a standard uniform random variable on the probability $([0,1], \cB_{[0,1]}, \lambda|_{[0,1]})$ this also implies the last part. 


which finished the proof.

\bigskip

\textbf{Problem 6.3}

\begin{enumerate}[label=(\alph*)]
\item For the probability space, take $\Omega = [0,1]$, $\cF = \cB_{[0,1]}$ and $\bbP = \lambda$ the Lebesgue measure restricted to $[0,1]$. 

Observe that the function $H_\gamma(z)$ is continuous and hence has an inverse $g_\gamma(y) = \gamma \tan(\pi(y - 1/2))$ on $[0,1]$.

So the function $Y [0,1] \to \bbR$ defined by $Y(x) = g_\gamma(x)$ has the correct distribution as
\[
	\bbP(Y^{-1}((-\infty,t])) = \bbP(g_\gamma^{-1}((-\infty, t])) = \lambda(H_\gamma((-\infty,t])) = H_\gamma(t).
\]
\item Note that $g_\gamma$ is continuous on $[0,1]$ and hence measurable.
\item For any $t \ge 0$, the cdf of the Poisson random variable is given by
\[
	F_\lambda(t) = \sum_{n = 0}^{\lceil t \rceil} f_\lambda(n),
\]
where $\lceil t \rceil$ is the ceiling of $t$, i.e. the smallest integer $k \ge t$.
\item For the probability space, we again take $\Omega = [0,1]$, $\cF = \cB_{[0,1]}$ and $\bbP = \lambda$ the Lebesgue measure restricted to $[0,1]$. 

Now for any $y \in [0,1]$ let $k := k(y)$ be such that
\[
	\sum_{n = 1}^k f_\lambda(n) \ge y \quad \text{and} \quad \sum_{n = 1}^{k-1} f_\lambda(n) < y,
\]
where the last sum is interpreted as $-1$ if $k=0$.

Now define $X(y) = k(y) : [0,1] \to \bbR$. Then $k(y) \le t$ if and only if $y \le F_\lambda(t)$ and hence
\[
	X^{-1}((-\infty,t]) = \{y \in [0,1] \, : \, k(y) \in (0,t]\}
	= \{y \in [0,1] \, : \, y \in (0, F_\lambda(t)]\},
\]
from which it follows that
\[
	\bbP(X^{-1}((-\infty,t])) = \lambda((0, F_\lambda(t)]) = F_\lambda(t).
\]
\item It follows from the above computation that $X^{-1}((-\infty,t]) = \{y \in [0,1] \, : \, y \in (0, F_\lambda(t)]\}$. Since the latter is a measurable set we conclude that $X^{-1}((-\infty,t])$ is measurable for all $t$ and since these generate the Borel \sigalg/ $X$ is measurable.
\item for any $\ell \in \bbN$ define the sets $A_\ell = (n-1-1/\ell), n-1 + 1/\ell]$. Then $A_\ell$ is a decreasing set with $\lim_{\ell \to \infty} A_\ell = \{n\}$. Moreover, $A_\ell = (-\infty,n-1+1/\ell] \setminus (-\infty, n-1-1/\ell]$ and $\bbP(A_1) < \infty$. It now follows from continuity from above and (d) that
\begin{align*}
	X_\#\bbP(\{n\}) &= \lim_{\ell \to \infty} X_\# \bbP(A_\ell) \\
	&= \lim_{\ell \to \infty} X_\# \bbP((-\infty,n-1+1/\ell])
	- X_\# \bbP((-\infty,n-1-1/\ell]) \\
	&= F_\lambda(n-1+1/\ell) - F_\lambda(n-1-1/\ell) \\
	&= \sum_{k = 0}^{n} f_\lambda(k) - \sum_{k = 0}^{n-1} f_\lambda(k) = f_\lambda(n).
\end{align*}
\end{enumerate}

\bigskip

\textbf{Problem 6.5}

Define for any $j \in \mathbb{Z}$, $p_j := \bbP(X^{-1}(\{j\}))$. Then, since $(X^{-1}(j))_{j \in \mathbb{Z}}$ is a family of disjoint sets and $\bbP$ is a probability measure we get that
\[
	1 = \bbP(\Omega) = \bbP(\bigcup_{j \in \mathbb{Z}} X^{-1}(j)) = \sum_{j \in \mathbb{Z}} p_j.
\]

Now let $A \subset \bbR$ be a measurable set and note that 
\[
	X^{-1}(A) = \bigcup_{j \in \mathbb{Z} \cap A} X^{-1}(j).
\]
Then it follows that
\[
	\bbP(X \in A) = \bbP(X^{-1}(A)) = \bbP\left(\bigcup_{j \in \mathbb{Z} \cap A} X^{-1}(j)\right)
	= \sum_{j \in \mathbb{Z} \cap A} p_j = \sum_{j \in \mathbb{Z}} \delta_j(A) p_j. 
\]

\bigskip

\textbf{Problem 6.7}

\begin{enumerate}[label=(\alph*)]
\item (3 pts) 

\textbf{1 pt} We first observe that 
\[
	\nu((-\infty,t]) = X_\# \bbP((-\infty,t])
\]
holds by definition of the pdf. 

\textbf{1 pt}
Next we note that the collection $\mathcal{A} := \{(-\infty, t] \, : \, t \in \bbR\}$ generates $\cB$ and satisfies the conditions of Theorem 2.15:
\begin{enumerate}
\item $(-\infty, t] \cap (-\infty ,s] = (-\infty, \min\{t,s\}] \in \mathcal{A}$, and
\item the sets $A_n (-\infty,n] \in \mathcal{A}$ for $n \in \bbN$ satisfies $\bigcup_{n \in \bbN} A_n = \bbR$.
\end{enumerate}

\textbf{1 pt}
Thus, since $\nu = X_\# \bbP$ on $\mathcal{A}$, by Theorem 2.15 we conclude that $\nu = X_\# \bbP$ on $\sigma(\cA_2) = \cB$.

\item (2 pts) Let $g = \sum_{i = 1}^N a_i \mathbbm{1}_{A_i}$ be a simple function. Then by definition of $\nu$ and linearity of the integral we get
\begin{align*}
	\int_\bbR g \, \dd \nu &= \sum_{i = 1}^N a_i \int_{A_i} \dd \nu\\
	&= \sum_{i = 1}^N a_i \nu(A_i) \\ 
	&= \sum_{i = 1}^N a_i \int_{A_i} \rho \, \dd \lambda \\
	&= \int_{\Omega} \sum_{i = 1}^N a_i \mathbbm{1}_{A_i} \rho \, \dd \lambda
	= \int_\bbR g \rho \, \dd \lambda.
\end{align*}
\item (2 pts) By using (b) and monotone convergence twice we get
\begin{align*}
	\int_\bbR h \, \dd \nu &= \int_\bbR \lim_{n \to \infty} [h]_n \, \dd \nu \\
	&= \lim_{n \to \infty} \int_\bbR [h]_n \, \dd \nu \\
	&= \lim_{n \to \infty} \int_\bbR [h]_n \rho \, \dd \lambda \\
	&= \int_\bbR \lim_{n \to \infty} [h]_n \rho \, \dd \lambda = \int_\bbR h \rho \, \dd \lambda.
\end{align*}
\item (1 pt) Using the change of variables result (Proposition 4.14) (a) and (c) we get
\[
	\bbE[h(X)] = \int_\Omega h \circ X \, \dd \bbP 
	= \int_{\bbR} h \, \dd X_\# \bbP = \int_\bbR h \, \dd \nu 
	= \int_\bbR h \rho \, \dd \lambda.
\]
\end{enumerate}

\bigskip

\textbf{Problem 6.8}

\begin{enumerate}[label=(\alph*)]
\item This follows from the following computation
\[
	\int_\Omega |f|^p \, \dd \mu \ge \int_{\Omega} |f|^p \mathbbm{1}_{|f| \ge t} \, \dd \mu
	\ge t^p \int_\Omega \mathbbm{1}_{|f| \ge t} \, \dd \mu
	= t^p \mu(\{\omega \in \Omega \, : \, |f| \ge t\}).
\]
\item Using the result for $p = 1$ we get
\[
	\bbP(|X| \ge t) = \mu(\omega \in \Omega \, : \, |X(\omega) \ge t \})
	\le \frac{1}{t} \int_{\Omega} X \, \dd \bbP = \frac{1}{t} \bbE[X].
\]
\item Take $f(\omega) = X(\omega) - \bbE[X]$, which is measurable. Then using the first result with $p = 2$ gives
\begin{align*}
	\bbP(|X - \bbE[X]| \ge t) &= \bbP(|X-\bbE[X]|^2 \ge t^2) \\
	&\le \frac{1}{t^2} \bbE[(X - \bbE[X])^2] \\
	&= \frac{1}{t^2} (\bbE[X^2] - \bbE[X]^2) = \frac{\mathrm{Var}(X)}{t^2}.
\end{align*}
\end{enumerate}


%###################################### Old Numbering ####################################
%
%
%\textbf{Problem 6.4}
%From Theorem~6.5.9, we find for any $\varepsilon>0$ a continuous and bounded function $g\in L^1(\Omega,\mu)$ such that
%\[
%	\|f-g\|_1 <\frac{\varepsilon}{2}.
%\]
%Let $M>0$ and set $g_M:= \varphi_M g$, where is a continuous function with compact support satisfying $0\le \varphi_M \le 1$, $\varphi_M\equiv 1$ on $\overline{B_M}$ and $\varphi_M\equiv 0$ on $B_{M+1}^c$. Notice that
%	\begin{align*}
%		\int_{\bbR^d} |g-g_M|\,\dd\mu = \int_{B_M^c} g\,\dd\mu \le \|g\|_{\sup}\,\mu(B_M^c).
%	\end{align*}
%Since $\mu$ is finite, the continuity from above of $\mu$ gives $\lim_{M\to\infty} \mu(B_{M}^c) = 0$. Hence, we find some $M=M_\varepsilon>0$ such that
%\[
%	\int_{\bbR^d} |g-g_M|\,\dd\mu < \frac{\varepsilon}{2}.
%\]
%Altogether, we've found some $g_M$ such that
%\[
%	\|f-g_M\|_1 \le \|f-g\|_1 + \|g-g_M\| < \varepsilon.
%\]